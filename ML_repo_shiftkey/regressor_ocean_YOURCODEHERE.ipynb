{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SHIFTKEY x ACENET: Machine Learning Basics**\n",
    "**Module 2: Implementations of Machine Learning -- Regression**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Here we will be doing a classification analysis on a generated dataset that represents the phytoplankton concentration in the ocean.\n",
    "\n",
    "Read about phytopanton here:\n",
    "\n",
    "https://en.wikipedia.org/wiki/Phytoplankton\n",
    "\n",
    "The features that were generated to calculate this concentration are:\n",
    "\n",
    "- sea surface temperature\n",
    "- nutrient levels\n",
    "- sunlight hours\n",
    "\n",
    "These variables are generated by a normal distribution, a gamma distribution, and a normal distribution, respectively.\n",
    "\n",
    "There are then added together in the form:\n",
    "\n",
    "$\\text{phytoplankton concentration} = \\sin(\\text{sea surface temperature}) + (\\text{nutrient levels})^2 + e^{\\text{sunlight hours}}$\n",
    "\n",
    "These distributions and the equation were arbitrarily designed to show how different regression methods work. I encourage you to mess around with these, change up the distributions etc and see how the analysis may change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORT DATA\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis demonstrates how to use machine learning, specifically deep learning with PyTorch, to model and predict phytoplankton concentration based on oceanographic variables, showcasing a non-linear relationship.\n",
    "\n",
    "We are going to generate data with a non-linear relationship and add noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data with a non-linear relationship\n",
    "np.random.seed(1997)\n",
    "\n",
    "num_samples = 10000\n",
    "\n",
    "def generate_data(n):\n",
    "    # # I encourage you to mess around with the values for these distributions or even try different distributions, for example a normal/gaussian?\n",
    "    # sst = np.random.uniform(10, 30, n)  # sea surface temperature (°c)\n",
    "    # nutrient_levels = np.random.uniform(0.5, 3.0, n)  # nutrient levels (arbitrary units)\n",
    "    # sunlight_hours = np.random.uniform(8, 16, n)  # daily sunlight hours\n",
    "\n",
    "    sst = np.random.normal(loc=25, scale=5, size=n)  # Normal distribution for sea surface temperature\n",
    "    nutrient_levels = np.random.gamma(shape=2, scale=1, size=n)  # Gamma distribution for nutrient levels\n",
    "    sunlight_hours = np.random.normal(loc=12, scale=2, size=n)\n",
    "\n",
    "    # Ensure all data is within realistic bounds\n",
    "    sst = np.clip(sst, 10, 40)  # Clip SST values to be within realistic range, e.g., 10°C to 30°C\n",
    "    # nutrient_levels = np.clip(nutrient_levels, 0.5, 3.0)  # Clip nutrient levels to a reasonable range\n",
    "    sunlight_hours = np.clip(sunlight_hours, 6, 16)\n",
    "\n",
    "    # # non-linear relation: phytoplankton concentration (sinx, x, x)\n",
    "    # phyto_concentration = (\n",
    "    #     2.5 * sst + \n",
    "    #     10 * np.sin(0.3 * sst) + \n",
    "    #     6 * nutrient_levels + \n",
    "    #     (-3.5) * sunlight_hours + \n",
    "    #     np.random.normal(0, 3, n)\n",
    "    # ) + 50\n",
    "\n",
    "    # more non-linear relation: phytoplankton concentration (sinx, x^2, e^x)\n",
    "    phyto_concentration = (\n",
    "        2.5 * sst + \n",
    "        10 * np.sin(0.3 * sst) + \n",
    "        10 * 6 * np.power((1/6**2) *nutrient_levels,2) + \n",
    "        (-3.5) * np.exp((1/np.exp(3.5))*sunlight_hours) + \n",
    "        np.random.normal(0, 3, n)\n",
    "    ) + 50\n",
    "\n",
    "    # stack features together\n",
    "    X = np.vstack((sst, nutrient_levels, sunlight_hours)).T\n",
    "    y = phyto_concentration.reshape(-1, 1)\n",
    "\n",
    "    return(X,y,sst,nutrient_levels,sunlight_hours,phyto_concentration)\n",
    "\n",
    "X,y,sst,nutrient_levels,sunlight_hours,phyto_concentration = generate_data(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot the distributions of the data we generated. always do this!!\n",
    "\n",
    "# set up the figure with subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
    "\n",
    "# plot the distributions\n",
    "sns.histplot(sst, bins=30, kde=True, ax=axes[0, 0], color=\"blue\")\n",
    "axes[0, 0].set_title(\"Distribution of Sea Surface Temperature (°C)\")\n",
    "\n",
    "sns.histplot(nutrient_levels, bins=30, kde=True, ax=axes[0, 1], color=\"green\")\n",
    "axes[0, 1].set_title(\"Distribution of Nutrient Levels\")\n",
    "\n",
    "sns.histplot(sunlight_hours, bins=30, kde=True, ax=axes[1, 0], color=\"orange\")\n",
    "axes[1, 0].set_title(\"Distribution of Daily Sunlight Hours\")\n",
    "\n",
    "sns.histplot(phyto_concentration, bins=30, kde=True, ax=axes[1, 1], color=\"purple\")\n",
    "axes[1, 1].set_title(\"Distribution of Phytoplankton Concentration\")\n",
    "\n",
    "# adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "feature_names = ['SST (°C)', 'Nutrient Levels', 'Sunlight Hours']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    axes[i].scatter(X[:, i], y, alpha=0.6)\n",
    "    axes[i].set_xlabel(feature_names[i])\n",
    "    axes[i].set_title(f'Phyto Conc. vs {feature_names[i]}')\n",
    "    axes[i].grid(True)\n",
    "\n",
    "axes[0].set_ylabel('Phytoplankton Concentration')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REMEMBER TO SPLIT YOUR DATA (why? think about it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and testing sets (80/20 split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the data preprocessing. This is where you would deal with empty data entries with imputation (imputation = replacing missing values).\n",
    "\n",
    "Read about imputation:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/impute.html\n",
    "\n",
    "You also scale the data.\n",
    "\n",
    "Read about scaling:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "And when you use a PyTorch neural network, you must convert your NumPy arrays into PyTorch tensors. These are just yet another different type of data type. For one these are called tensors, but they aren't actually tensors like the ones we talk about in differential geometry or general relativity. Similar to now NumPy arrays are an extension of Python lists to make computations more efficient, PyTorch tensors are an extension of NumPy arrays to make computations with neural networks more efficient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA PREPROCESSING\n",
    "\n",
    "# # standardize features (important for neural networks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions (on which X?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # evaluate model performance\n",
    "\n",
    "# plt.figure()\n",
    "# plt.scatter(y_val_pred, y_val, alpha=0.5)\n",
    "# plt.plot([min(y_val), max(y_val)], [min(y_val), max(y_val)], '--', color='red')\n",
    "# plt.title(\"Actual vs Predicted (validation)\")\n",
    "# plt.xlabel(\"Actual\")\n",
    "# plt.ylabel(\"Predicted\")\n",
    "# plt.show()\n",
    "\n",
    "# # calculate mean squared error, this tells us the average squared difference between the predicted and true values. so let's take the square root\n",
    "# val_rmse = np.sqrt(mean_squared_error(y_val, y_val_pred)) # root mean squared error\n",
    "\n",
    "# # r^2 tells us how well the model explains the variance in the data. an r^2 of 1 is a perfect correlation and a r^2 of  0 is no correlation\n",
    "# val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# # print out the metrics we just calculated\n",
    "# print(f\"Validation RMSE: {val_rmse}\") # this number is very large so we print the log10 of it\n",
    "# print(f\"Validation R2 Score: {val_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test,y_test,nutrient_levels_,sunlight_hours_,phyto_concentration_ = generate_data(200)\n",
    "\n",
    "# np.random.seed(2025)\n",
    "# num_test_samples = int(0.2*num_samples)\n",
    "# print(f'predicting {num_test_samples} samples')\n",
    "# X_test,y_test,sst_test,nutrient_levels_test,sunlight_hours_test,phyto_concentration_test = generate_data(num_test_samples)\n",
    "\n",
    "# X_test = scaler.transform(X_test) # apply the datapreprocessing\n",
    "\n",
    "# # use model\n",
    "# y_test_pred = model.predict(X_test)\n",
    "\n",
    "# # calculate evaluation metrics\n",
    "# test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "# test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.hist(y_test_pred,bins = 50,alpha = 0.8,density = True, label = 'pred')\n",
    "# plt.hist(y_test,bins = 50,alpha = 0.6,density = True, label = 'true')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we visualize our results and look at the performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # visualization\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# # sns.scatterplot(x=y_test.flatten(), y=test_predictions.flatten(), label=\"Predicted vs. Actual\", color=\"blue\", alpha=0.7)\n",
    "# sns.scatterplot(x=y_test.flatten(), y=y_test_pred.flatten(), label=\"Predicted vs. Actual\", color=\"blue\", alpha=0.7)\n",
    "# plt.plot([y.min(), y.max()], [y.min(), y.max()], color=\"red\", linestyle=\"--\", label=\"Ideal Fit\")\n",
    "# plt.xlabel(r\"Actual Phytoplankton Concentration (mg/m$^3$)\")\n",
    "# plt.ylabel(r\"Predicted Concentration (mg/m$^3$)\")\n",
    "# plt.title(\"Neural Network Regression: Phytoplankton Prediction\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# # print evaluation metrics\n",
    "# print(f\"test mse: {test_mse:.2f}\")\n",
    "# print(f\"test r^2 score: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names = ['SST (°C)', 'Nutrient Levels', 'Sunlight Hours']\n",
    "# fig, axes = plt.subplots(1, 3, figsize=(15, 4), sharey=True)\n",
    "\n",
    "# # X_test_plot = X_test\n",
    "# X_test_plot = scaler.inverse_transform(X_test)\n",
    "\n",
    "# for i in range(X.shape[1]):\n",
    "#     axes[i].scatter(X_test_plot[:, i], y_test_pred, alpha=0.6, c = 'k',label = 'pred')\n",
    "#     axes[i].scatter(X_test_plot[:, i], y_test, alpha=0.2,c = 'r', label = 'true')\n",
    "#     axes[i].set_xlabel(feature_names[i])\n",
    "#     axes[i].set_title(f'Phyto Conc. vs {feature_names[i]}')\n",
    "#     axes[i].grid(True)\n",
    "\n",
    "# axes[0].set_ylabel('Phytoplankton Concentration')\n",
    "# plt.tight_layout()\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
