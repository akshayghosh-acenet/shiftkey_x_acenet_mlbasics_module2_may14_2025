{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KlPp15y6s_hd"
   },
   "source": [
    "## **SHIFTKEY x ACENET: Machine Learning Basics**\n",
    "**Module 2: Implementations of Machine Learning -- Classification**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Here we will be doing a classification analysis on the Iris dataset.\n",
    "\n",
    "Read about the dataset here:\n",
    "\n",
    "https://scikit-learn.org/1.4/auto_examples/datasets/plot_iris_dataset.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Iris_flower_data_set\n",
    "\n",
    "\n",
    "We will walk through:\n",
    "\n",
    "1. Importing relevant libraries\n",
    "2. Loading the dataset\n",
    "3. Exploratory data analysis\n",
    "4. Data preprocessing\n",
    "5. Define the model\n",
    "6. Fit model and make predictions\n",
    "7. Evaluate model\n",
    "8. Use grid search for better statistics\n",
    "9. Hyperparameter tuning to optimize model\n",
    "10. Feature importance to get insights on model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tr63lVSawTAt"
   },
   "source": [
    "**1. Import libraries**\n",
    "\n",
    "First, we important the libraries that we will need for our analysis. When doing your own analysis you might add these as you go along, which is good, when you do that it is typical and organized to keep them all at the top of your code.\n",
    "\n",
    "An overview of some of these libraries:\n",
    "\n",
    "**Matplotlib:** Plotting.\n",
    "\n",
    "**Seaborn:** More plotting.\n",
    "\n",
    "**Pandas:** Manipulation of dataframes.\n",
    "\n",
    "**NumPy:** Create arrays, use mathematical functions.\n",
    "\n",
    "**Scikit-learn:** Machine learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCiRt3NKC5os"
   },
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIFJrI0Aw8Xg"
   },
   "source": [
    "**2. Loading the dataset**\n",
    "\n",
    "Now we load the Iris dataset. For practice purposes, we are using an ```sklearn``` dataset, so that we can focus on the machine learning. In practice, this will be more involved.\n",
    "\n",
    "We will use the Iris extended dataset which can be downloaded here:\n",
    "\n",
    "https://www.kaggle.com/datasets/samybaladram/iris-dataset-extended?resource=download&select=iris_extended.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 76
    },
    "executionInfo": {
     "elapsed": 4411,
     "status": "ok",
     "timestamp": 1746812049791,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "nVaINntT31bN",
    "outputId": "42db6726-78aa-489f-94f0-388d7b02b4fe"
   },
   "outputs": [],
   "source": [
    "# iris = load_iris(as_frame=True)\n",
    "local = True\n",
    "\n",
    "if not local:\n",
    "    from google.colab import files\n",
    "    uploaded = files.upload()\n",
    "\n",
    "    # download here: https://www.kaggle.com/datasets/samybaladram/iris-dataset-extended?resource=download\n",
    "    fn = 'iris_extended.csv'\n",
    "else:\n",
    "    fn = './iris_extended.csv'\n",
    "\n",
    "data = pd.read_csv(fn)\n",
    "\n",
    "# create a target column\n",
    "species_mapping = {\n",
    "    \"setosa\": 0,\n",
    "    \"versicolor\": 1,\n",
    "    \"virginica\": 2\n",
    "}\n",
    "data[\"target\"] = data[\"species\"].map(species_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 660
    },
    "executionInfo": {
     "elapsed": 73,
     "status": "ok",
     "timestamp": 1746812070816,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "WFdaVVyqF53j",
    "outputId": "41794ba1-b5ef-4aba-bbcd-d9d1c44ae197"
   },
   "outputs": [],
   "source": [
    "# look at the columns, examine the top 10 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axIUKyZCGD3L"
   },
   "outputs": [],
   "source": [
    "# select features i.e. the columns that we want to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BAb9iq-vxZcN"
   },
   "source": [
    "**3. Exploratory data analysis**\n",
    "\n",
    "Now we do Exploratory Data Analysis, also known as EDA, to examine our dataset. It is very important to understand your dataset in order to conduct a meaningful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3984,
     "status": "ok",
     "timestamp": 1746812093723,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "GAs7Kp0gC3u4",
    "outputId": "4cd0814d-aaf0-4625-b1bd-4bcd75ac05cf"
   },
   "outputs": [],
   "source": [
    "# exploratory data analysis, plot the distributions, the pairplot, the correlation matrix\n",
    "\n",
    "# distributions\n",
    "\n",
    "\n",
    "# pairplot\n",
    "\n",
    "\n",
    "# correlation matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8FA_nijYyYrg"
   },
   "source": [
    "**4. Data preprocessing**\n",
    "\n",
    "Now we do our data preprocessing, where we prepare the data to be input to the model. Since we are using the Iris dataset there is not too much to do in this particular instance, but typically this involves:\n",
    "\n",
    "**Imputation:** Filling in missing values through various methods.\n",
    "https://scikit-learn.org/stable/modules/impute.html\n",
    "\n",
    "**Scaling:** Scale features of the data to be within a certain range (for example 0 to 1).\n",
    "https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "ONE METHOD (key emphasis on one of many) is to use the ```sklearn``` method called ```Pipeline```. This allows for an easy way to chain together the preprocessing steps with the model in a way that we will know what works. When using ```sklearn``` machine models I like to use this. If you want to use a different library, for example if you are doing deep learning and using ```PyTorch``` to create a neural network, you will need to manually apply the preprocesssing transformations to your data. If you would like to learn more about this, keep an eye out for ACENET's upcoming training sessions!\n",
    "\n",
    "NOTE:\n",
    "\n",
    "We use $X$ to represent our inputs aka the features.\n",
    "\n",
    "We use $y$ to represent our output aka the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pgXYePIHF5-2"
   },
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "\n",
    "# set up X and y\n",
    "\n",
    "\n",
    "\n",
    "# get numeric features\n",
    "\n",
    "\n",
    "\n",
    "# set up numeric transformer\n",
    "\n",
    "\n",
    "\n",
    "# put together into preprocessor object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZube6qm0wSZ"
   },
   "source": [
    "**5. Define the model**\n",
    "\n",
    "Now we define our classifier model. Keep an eye on the parameters we select, these are what we fine-tune later.\n",
    "\n",
    "We then call the ```sklearn.Pipeline``` method to chain together our preprocessor and our classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gBnXGBzBJh9J"
   },
   "outputs": [],
   "source": [
    "# select model we will use random forest classifier\n",
    "\n",
    "# define classifier\n",
    "\n",
    "\n",
    "# link the preprocessor and the model in the pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXGiIzjs1Gll"
   },
   "source": [
    "Now, we split the dataset into training and testing subsets. This is because we want to use a portion of the data to \"fit\" the model, and a **SEPARATE** portion of the data to test and evaluate the model.\n",
    "\n",
    "**IT IS EXTREMELY IMPORTANT THAT THE TRAINING AND TESTING SUBSETS DO NOT MIX, OR YOUR MODEL IS COMPLETELY INVALID!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NLo-AjI0KSv6"
   },
   "outputs": [],
   "source": [
    "# now split the data for fitting\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W7yeTJbv1tl8"
   },
   "source": [
    "**6. Fit model and make predictions**\n",
    "\n",
    "Now we fit the model. Since we used the ```Pipeline```, this very simple where we can just do ```iris_model.fit``` and it will automatically apply the preprocessing and then do the fit to learn the model weights. Remember that you **fit** with the **training** data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "executionInfo": {
     "elapsed": 259,
     "status": "ok",
     "timestamp": 1746812497058,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "PhvYEbiwKqpe",
    "outputId": "49ee40a9-a2fb-4f1b-8565-b6c2c7e6919f"
   },
   "outputs": [],
   "source": [
    "# now fit the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA5lplW78ah4"
   },
   "source": [
    "**7. Evaluate model**\n",
    "\n",
    "Now that we have fit the model, we can make predictions on the testing data and evaluate the model. Recall the precision, recall, and F1-score from Module 1 last week.\n",
    "\n",
    "We also calculate the confusion matrix display which summarizes the performance of a classification model by comparing the true labels to the predicted labels. This gives us a more detailed evaluation of the model that cannot be quantified with just a single number. Ideally the largest values in the matrix would be on the diagonal. Large values off the diagonal to a certain direction (upper or lower part of the matrix) could indicate a systematic bias in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1746812501951,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "izCMK3D0MD8I",
    "outputId": "ce505236-f94a-41ac-f852-2e277f0d3586"
   },
   "outputs": [],
   "source": [
    "# now that the model is fit, predict the testing data and do evaluation metrics\n",
    "\n",
    "# calculate predictions on the TEST data\n",
    "\n",
    "#  calculate the classification report and confusion matrix\n",
    "species_names = ['setosa','versicolor','virginica']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.1 Feature importance**\n",
    "\n",
    "Now we calculate the feature importance. In supervised learning tasks like this classification, not all of the input features will contribute equally to the outcome. Some of the features will be a stronger predictor of the target, and others may be weaker predictors or redundant.\n",
    "\n",
    "Understanding the feature importance in your model can help with interpreting the model as you can see how each feature effects the output. This could be very useful for example in a science experiement, as you could see which measurements affect the outcome the most which can help to inform future studies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1746812513312,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "BZHWi2OgTcIX",
    "outputId": "70ccb00d-294c-4703-cb30-dafa625b7e20"
   },
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE\n",
    "\n",
    "# get feature importance from classifier model\n",
    "\n",
    "# match feature importance with feature names\n",
    "\n",
    "# sort by importance\n",
    "\n",
    "# print top features\n",
    "\n",
    "# plot feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Cross validation for better statistics**\n",
    "\n",
    "Before we were splitting the data into a single instance of training and validation subsets, the model was fit with the training data, and then evaluated on the validation data. \n",
    "\n",
    "This is a very valid method, but keep this in mind: When we do this split and get performance metrics like accuracy, confusion matrix, etc, these are basically one possible calculation of the performance metrics. These metrics could change if we split the data differently!\n",
    "\n",
    "For example, let's say our data consists of `A,B,C,D,E`. If we use `A,B,C,D` for training and then `E` for validation, that will give us a set of performance metrics.\n",
    "\n",
    "What if we did the analysis 5 times with the following combinations:\n",
    "\n",
    "Training: `A,B,C,D`, Validation: `E`\n",
    "\n",
    "Training: `A,B,C,E`, Validation: `D`\n",
    "\n",
    "Training: `A,B,D,E`, Validation: `C`\n",
    "\n",
    "Training: `A,C,D,E`, Validation: `B`\n",
    "\n",
    "Training: `B,C,D,E`, Validation: `A`\n",
    "\n",
    "And then averaged the performance metrics from each of these experiments? This would give us a more robust idea of the performance of the model that is less dependent on the specific training and validation split that we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1482,
     "status": "ok",
     "timestamp": 1746812518801,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "AJ0YnbTYS05Q",
    "outputId": "2ff8dda1-80ba-4731-c0b7-52cd2b2959df"
   },
   "outputs": [],
   "source": [
    "# now use cross_val_score to fit and predict the model over multiple train/test splits\n",
    "\n",
    "\n",
    "\n",
    "# print results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9. Hyperparameter tuning**\n",
    "\n",
    "Remember we defined our classifier model like this:\n",
    "\n",
    "classifier = RandomForestClassifier(\n",
    "    n_estimators=100,            # number of trees in the forest\n",
    "    max_depth=None,              # maximum depth of each tree (None = expand until all leaves are pure)\n",
    "    min_samples_split=2,         # minimum number of samples required to split an internal node\n",
    "    random_state=1997            # ensures reproducibility\n",
    ")\n",
    "\n",
    "How can we decide these parameters like number of estimators or max depth? We can guess, run the model, and look at the performance metrics. We can then make slightly different guesses and repeat the process. Hyperparameter tuning is a systematic way of automating this process.\n",
    "\n",
    "We use grid search parameter tuning, where we define a grid of parameters to test, and every combination is then tested.\n",
    "\n",
    "The `sklearn` function `GridSearchCV` combines the grid search for hyperparameter tuning with the cross validation (where you set the number of folds with the parameter `cv`). From the results you can then load the best model.\n",
    "\n",
    "There are also other methods for hyperparameter tuning like random search, where you can define a larger grid and instead of every possible combinations, combinations are chosen at random. There is also Bayesian search where statistics are used to find the best combination of hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14883,
     "status": "ok",
     "timestamp": 1746812585485,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "78OibgvTRdnY",
    "outputId": "2bf5e3c8-f98f-421f-f94e-13af5f5aa0aa"
   },
   "outputs": [],
   "source": [
    "# hyperparameter tuning to find the best model\n",
    "\n",
    "# set up param grid\n",
    "\n",
    "\n",
    "# use that with grid search\n",
    "\n",
    "\n",
    "# print best params and corresponding score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 455
    },
    "executionInfo": {
     "elapsed": 707,
     "status": "ok",
     "timestamp": 1746812686227,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "jiQri7-vU2cN",
    "outputId": "2f1b9e5e-8e93-42a0-a6ab-8461816eb722"
   },
   "outputs": [],
   "source": [
    "# now do predictions with the best model and look at the confusion matrix again\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 656
    },
    "executionInfo": {
     "elapsed": 137,
     "status": "ok",
     "timestamp": 1746812693034,
     "user": {
      "displayName": "Akshay Ghosh",
      "userId": "16212663093929183606"
     },
     "user_tz": 180
    },
    "id": "YVr2cmJgVle6",
    "outputId": "830ed0dc-227e-4384-987a-668b2377af07"
   },
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE AGAIN\n",
    "\n",
    "# # get feature importance from best xgb model\n",
    "# feature_importance = best_model.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# # match feature importance with feature names\n",
    "# feature_names = X_train.columns\n",
    "# feature_importance_df = pd.DataFrame({'Feature': feature_names,\n",
    "#                                       'Importance': feature_importance})\n",
    "\n",
    "# # sort by importance\n",
    "# feature_importance_df = feature_importance_df.sort_values(by='Importance',ascending=False)\n",
    "\n",
    "# # print top features\n",
    "# print(feature_importance_df)\n",
    "\n",
    "# # plot feature importance\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'], color='skyblue')\n",
    "# plt.xlabel(\"Feature Importance\")\n",
    "# plt.ylabel(\"Features\")\n",
    "# plt.title(\"Feature Importance on Predicting Iris Species in RandomForestClassifier Model\")\n",
    "# plt.gca().invert_yaxis()  # Invert axis to show highest importance at the top\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOKpCIm0QaRulcVGQi5JKIq",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
